What is the project about? 
This project explores whether neural network parsers are able to capture human-like syntactic processing difficulty according to surprisal scores.
An LSTM was trained on simple English sentences and tested on a syntactically more complicated structure containing a center-embedded clause.
The objective was to find out if the model provides greater surprisal to more complex sentences, since human cognitive effort in sentence understanding.
What is my Research Question
Can neural network parsers simulate human-like syntactic processing difficulty, as reflected through surprisal scores?
Methods
Trained an LSTM model on basic English data.
Calculated surprisal scores for basic and compound sentences.
Compared surprisal patterns with typical human processing behavior.
Results
Sub-compound test sentences averaged higher surprisal scores (~5.4â€“6.6) compared to simpler training sentences.
Verifies that the model is syntactically complex sensitive, like human cognitive patterns.